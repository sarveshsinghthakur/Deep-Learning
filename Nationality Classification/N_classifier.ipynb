{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81c94e8c",
        "outputId": "f4fe7b8c-8c28-4d7d-d745-2b31ca087fb4"
      },
      "source": [
        "!pip install tensorflow keras faker"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: faker in /usr/local/lib/python3.12/dist-packages (37.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras) (0.17.0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.12/dist-packages (from faker) (2025.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "4efd2199"
      },
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer, sequence\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.callbacks import Callback\n",
        "from faker import Faker\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7213cfba"
      },
      "source": [
        "female_data = pd.read_csv('/content/Indian-Female-Names.csv')\n",
        "male_data = pd.read_csv(\"/content/Indian-Male-Names.csv\")"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bf6ad21",
        "outputId": "e7eab0d5-38ce-44e3-a45c-26fe1bbec0e4"
      },
      "source": [
        "repl_list = ['s/o','d/o','w/o','/','&',',','-']\n",
        "\n",
        "def clean_data(name):\n",
        "        name = str(name).lower()\n",
        "        name = (''.join(i for i in name if ord(i)<128)).strip()\n",
        "        for repl in repl_list:\n",
        "                name = name.replace(repl,\" \")\n",
        "        if '@' in name:\n",
        "                pos = name.find('@')\n",
        "                name = name[:pos].strip()\n",
        "        name = name.split(\" \")\n",
        "        name = \" \".join([each.strip() for each in name])\n",
        "        return name\n",
        "\n",
        "def remove_records(merged_data):\n",
        "        merged_data['delete'] = 0\n",
        "        merged_data.loc[merged_data['name'].str.find('with') != -1,'delete'] = 1\n",
        "        merged_data.loc[merged_data['count_words']>=5,'delete']=1\n",
        "        merged_data.loc[merged_data['count_words']==0,'delete']=1\n",
        "        merged_data.loc[merged_data['name'].str.contains(r'\\d') == True,'delete']=1\n",
        "        cleaned_data = merged_data[merged_data.delete==0]\n",
        "        return cleaned_data\n",
        "\n",
        "merged_data = pd.concat((male_data,female_data),axis=0)\n",
        "\n",
        "merged_data['name'] = merged_data['name'].apply(clean_data)\n",
        "merged_data['count_words'] = merged_data['name'].str.split().apply(len)\n",
        "\n",
        "cleaned_data = remove_records(merged_data)\n",
        "\n",
        "indian_cleaned_data = cleaned_data[['name','count_words']].drop_duplicates(subset='name',keep='first')\n",
        "indian_cleaned_data['label'] = 'indian'\n",
        "\n",
        "len(indian_cleaned_data)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13754"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36833d5e",
        "outputId": "55911d45-63e0-4d51-ad74-aa57c33b861e"
      },
      "source": [
        "fake = Faker(\"en_us\")\n",
        "non_indian_data_list = []\n",
        "for i in range(14000):\n",
        "  name = fake.name()\n",
        "  non_indian_data_list.append({'name':name,'count_words':len(name.split()),'label':'non_indian'})\n",
        "\n",
        "non_indian_data = pd.DataFrame(non_indian_data_list)\n",
        "len(non_indian_data)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14000"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fed3389d",
        "outputId": "57c73d02-1ccc-4b82-9f9c-afe6a521daa6"
      },
      "source": [
        "all_names = pd.concat([indian_cleaned_data, non_indian_data], ignore_index=True)\n",
        "train_data, test_data = train_test_split(all_names, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training data shape: {train_data.shape}\")\n",
        "print(f\"Testing data shape: {test_data.shape}\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (22203, 3)\n",
            "Testing data shape: (5551, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca5b7cab",
        "outputId": "80c0ee20-d21b-4a62-d7e8-8f542d075c5c"
      },
      "source": [
        "max_words = 10000\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(train_data['name'])\n",
        "train_sequences = tokenizer.texts_to_sequences(train_data['name'])\n",
        "test_sequences = tokenizer.texts_to_sequences(test_data['name'])\n",
        "max_sequence_length = 10\n",
        "train_padded = sequence.pad_sequences(train_sequences, maxlen=max_sequence_length, padding='post', truncating='post')\n",
        "test_padded = sequence.pad_sequences(test_sequences, maxlen=max_sequence_length, padding='post', truncating='post')\n",
        "\n",
        "print(f\"Shape of training sequences: {train_padded.shape}\")\n",
        "print(f\"Shape of testing sequences: {test_padded.shape}\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training sequences: (22203, 10)\n",
            "Shape of testing sequences: (5551, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de1d1d5e",
        "outputId": "101ecdd5-fb7d-4298-f5f3-1af9026e03ac"
      },
      "source": [
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_data['label'])\n",
        "test_labels_encoded = label_encoder.transform(test_data['label'])\n",
        "train_labels_one_hot = to_categorical(train_labels_encoded)\n",
        "test_labels_one_hot = to_categorical(test_labels_encoded)\n",
        "\n",
        "print(f\"Shape of training labels: {train_labels_one_hot.shape}\")\n",
        "print(f\"Shape of testing labels: {test_labels_one_hot.shape}\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training labels: (22203, 2)\n",
            "Shape of testing labels: (5551, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "bcbb03f9",
        "outputId": "1ad4c401-e31f-4231-faef-91a1817168cf"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_sequence_length))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(train_labels_one_hot.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b2830e6",
        "outputId": "30b1e479-8e6a-46f6-b5bb-220de90d241a"
      },
      "source": [
        "history = model.fit(train_padded, train_labels_one_hot, epochs=10, batch_size=32, validation_split=0.2)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.8423 - loss: 0.2694 - val_accuracy: 0.9973 - val_loss: 0.0130\n",
            "Epoch 2/10\n",
            "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 0.0025 - val_accuracy: 0.9964 - val_loss: 0.0131\n",
            "Epoch 3/10\n",
            "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0023 - val_accuracy: 0.9944 - val_loss: 0.0173\n",
            "Epoch 4/10\n",
            "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 8.0640e-04 - val_accuracy: 0.9975 - val_loss: 0.0114\n",
            "Epoch 5/10\n",
            "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0019 - val_accuracy: 0.9968 - val_loss: 0.0231\n",
            "Epoch 6/10\n",
            "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1401e-04 - val_accuracy: 0.9959 - val_loss: 0.0180\n",
            "Epoch 7/10\n",
            "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.9289e-04 - val_accuracy: 0.9971 - val_loss: 0.0235\n",
            "Epoch 8/10\n",
            "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.4621e-06 - val_accuracy: 0.9973 - val_loss: 0.0237\n",
            "Epoch 9/10\n",
            "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 9.7511e-07 - val_accuracy: 0.9973 - val_loss: 0.0239\n",
            "Epoch 10/10\n",
            "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.7501e-07 - val_accuracy: 0.9973 - val_loss: 0.0241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81c563ea",
        "outputId": "a1a56b1f-2b3a-4f65-e253-a081a5b0efa4"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_padded, test_labels_one_hot, verbose=0)\n",
        "\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0206\n",
            "Test Accuracy: 0.9982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "180ce948",
        "outputId": "467eaddc-616d-4cd0-918f-4e30cdc790d3"
      },
      "source": [
        "def predict_name_origin(names):\n",
        "    cleaned_names = [clean_data(name) for name in names]\n",
        "    name_sequences = tokenizer.texts_to_sequences(cleaned_names)\n",
        "    name_padded = sequence.pad_sequences(name_sequences, maxlen=max_sequence_length, padding='post', truncating='post')\n",
        "    predictions = model.predict(name_padded)\n",
        "    predicted_labels_encoded = np.argmax(predictions, axis=1)\n",
        "    predicted_labels = label_encoder.inverse_transform(predicted_labels_encoded)\n",
        "    return predicted_labels\n",
        "\n",
        "while True:\n",
        "  input_names_string = input('Enter a list of names separated by commas (or type \"exit\" to quit): ')\n",
        "  if input_names_string.lower() == 'exit':\n",
        "    break\n",
        "  new_names = input_names_string.split(',')\n",
        "  predicted_origins = predict_name_origin(new_names)\n",
        "\n",
        "  for name, origin in zip(new_names, predicted_origins):\n",
        "      print(f\"The name '{name}' is predicted as: {origin}\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a list of names separated by commas (or type \"exit\" to quit): nilesh\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
            "The name 'nilesh' is predicted as: indian\n",
            "Enter a list of names separated by commas (or type \"exit\" to quit): exit\n"
          ]
        }
      ]
    }
  ]
}