# -*- coding: utf-8 -*-
"""Toxicity measure.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GfvxQdYxlmTa4uxhRfyfBMuK6aticMc2
"""

!pip install tensorflow opencv-python gradio jinja2

"""# **Import Dependencies**"""

import pandas as pd
import numpy as np
import seaborn as ans
import matplotlib.pyplot as plt
import tensorflow as tf
import cv2
import os
from tensorflow.keras.layers import TextVectorization
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding
from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy
import gradio as gr

"""# **Preparing Dataset**"""

data = pd.read_csv('/content/train.csv')
data.head()

x = data['comment_text']
y = data[data.columns[2:]].values

vectors = TextVectorization(max_tokens=200000, output_sequence_length=1800, output_mode='int')

vectors.adapt(x.values)
x_vector = vectors(x.values)

total_elements = len(x_vector)
train_size = int(0.7 * total_elements)
val_size = int(0.2 * total_elements)
test_size = total_elements - train_size - val_size

dataset = tf.data.Dataset.from_tensor_slices((x_vector, y))
dataset = dataset.cache()
dataset = dataset.shuffle(160000)
dataset = dataset.batch(16)
dataset = dataset.prefetch(8)

train = dataset.take(train_size // 16 + (1 if train_size % 16 > 0 else 0))
val = dataset.skip(train_size // 16 + (1 if train_size % 16 > 0 else 0)).take(val_size // 16 + (1 if val_size % 16 > 0 else 0))
test = dataset.skip((train_size + val_size) // 16 + (1 if (train_size + val_size) % 16 > 0 else 0)).take(test_size // 16 + (1 if test_size % 16 > 0 else 0))

"""# **Building a Model : Sequential**"""

model = Sequential()
model.add(Embedding(200000+1, 32))
model.add(Bidirectional(LSTM(32, activation='tanh')))
model.add(Dense(128, activation='relu'))
model.add(Dense(256, activation='relu'))
model.add(Dense(128, activation='relu'))
model.add(Dense(6, activation='sigmoid'))

model.compile(loss='BinaryCrossentropy', optimizer='Adam')

"""# **Evaluating the model performance**"""

model.summary()

history = model.fit(train, epochs=1, validation_data=val)

plt.figure(figsize=(8,5))
pd.DataFrame(history.history).plot()
plt.show()

print(f"model accuracy : {model.evaluate(test)}")

"""# **Testing the model**"""

input_text = vectors("I wish you would die")

input_text = np.expand_dims(input_text, axis=0)

ans = model.predict(input_text)

(ans > 0.5).astype(int)

ans.shape

toxicity_categories = data.columns[2:]

binary_predictions = (ans > 0.5).astype(int)[0]
print("Toxicity Predictions:")
for category, prediction in zip(toxicity_categories, binary_predictions):
    print(f"{category}: {prediction}")

"""# **Save the model**"""

model.save("Toxicity_Finder.h5")

"""# **Use the saved model for prediction**"""

input_text_x = vectors("hey Your asshole !!!")

models = tf.keras.models.load_model('Toxicity_Finder.h5')

answer = models.predict(np.expand_dims(input_text_x,0))

answer

toxicity_categories = data.columns[2:]

binary_predictions = (answer > 0.5).astype(int)[0]
print("Toxicity Predictions:")
for category, prediction in zip(toxicity_categories, binary_predictions):
    print(f"{category}: {prediction}")

"""# Predict your text -> Toxicity level"""

def score_comment(comment):
    vectorized_comment = vectors([comment])
    results = models.predict(vectorized_comment)
    text = ''
    for idx, col in enumerate(data.columns[2:]):
        text += '{}: {}\n'.format(col, results[0][idx]>0.5)

    return text

interface = gr.Interface(fn=score_comment,
                         inputs=gr.Textbox(lines=2, placeholder='Comment to score'),
                        outputs='text')

interface.launch(share=True)